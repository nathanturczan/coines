{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datalogger and Format Handler\n",
    "The datalogger format handler provides scripts for handling the datalogger dataset format such as binary conversion to csv-format, meta data handling and labeling information extraction. Basically, the datalogger format handler offers two classes: <code>class GLP_Decoder()</code> for decoding binary format and <code>class DatasetFormatHandler()</code> for processing of the logged data, meta-data and labeling information.\n",
    "\n",
    "Author: Sergej Scheiermann (BST/ESW4)  \n",
    "Date: 2019-10-19  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import DataloggerFormatHandler as dlf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include Datasets for Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] following datasets included:\n",
      "\tC:\\Users\\ina8cob\\scripts\\tutorial_datalogger\\tutorial\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "datasetList = []\n",
    "datasetList.append('tutorial\\\\')\n",
    "\n",
    "print(\"[INFO] following datasets included:\")\n",
    "for dataset in datasetList:\n",
    "    print(\"\\t%s\"%(os.path.abspath(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Files Conversion to CSV-Format (only if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] start conversion job.\n",
      "[INFO]\t\tconverting file: C:\\Users\\ina8cob\\scripts\\tutorial_datalogger\\tutorial\\01_data\\bin\\LOG_AFD0ED_1603887725768.bin\n",
      "[INFO]\t\tconverting file: C:\\Users\\ina8cob\\scripts\\tutorial_datalogger\\tutorial\\01_data\\bin\\LOG_AFD0ED_1603887786067.bin\n",
      "[INFO] conversion job done. :-)\n"
     ]
    }
   ],
   "source": [
    "DO_CONVERSION = True # set to False if binary conversion are not required (e.g. was already converted)\n",
    "\n",
    "# check if conversion needed\n",
    "if DO_CONVERSION:\n",
    "    hndlr = dlf.DatasetFormatHandler()\n",
    "    print('[INFO] start conversion job.')\n",
    "    #### decode all binaries\n",
    "    for path in datasetList:\n",
    "        hndlr.convert_bin2csv(path)\n",
    "    print('[INFO] conversion job done. :-)')\n",
    "else:\n",
    "    print('[INFO] conversion job deactivated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datalogger Dataset Structure\n",
    "The data format handler implements generic datalogger format and meta information interfaces and helps to extract labels, configuratios and data from the datasets folders.\n",
    "\n",
    "The dataset contains meta folder (***00_meta***) and data folder (***01_data***).\n",
    "Every created dataset after all cenversions follows structure listed below:\n",
    "- \\yourdataset\n",
    "    - \\00_meta\n",
    "        - datasetInfo.json\n",
    "        - userinfo.txt\n",
    "        - fileinfo.txt\n",
    "        - activity.txt\n",
    "        - deviceConfig.json\n",
    "        - algoResults.txt\n",
    "    - \\01_data\n",
    "        - \\bin\n",
    "            - LOG_DEVID_UNIXTIMESTAMP_YOURLOGFILE1.bin\n",
    "            - LOG_DEVID_UNIXTIMESTAMP_YOURLOGFILE2.bin\n",
    "            - ...\n",
    "        - \\csv\n",
    "            - LOG_DEVID_UNIXTIMESTAMP_YOURLOGFILE1.csv\n",
    "            - LOG_DEVID_UNIXTIMESTAMP_YOURLOGFILE2.csv\n",
    "            - ...\n",
    "        - \\label\n",
    "            - LABEL_LOG_UNIXTIMESTAMP_YOURLOGFILE1.csv\n",
    "            - LABEL_LOG_UNIXTIMESTAMP_YOURLOGFILE2.csv\n",
    "            - ...            \n",
    "        - \\plots\n",
    "            - LOG_DEVID_UNIXTIMESTAMP_YOURLOGFILE1.png\n",
    "            - LOG_DEVID_UNIXTIMESTAMP_YOURLOGFILE2.png\n",
    "            - ...\n",
    "    - \\99_configs\n",
    "        - activities.json\n",
    "        - device_location.json\n",
    "\n",
    "\n",
    "## Meta Information\n",
    "The BST datalogger application contains the meta information for the logged files such as date of creation, \n",
    "For every binary file logged with datalogger application, meta information will be created.<br>\n",
    "Datalogger application (Android Apk: BST Datalogger) contains following meta information:\n",
    "* **datasetInfo.json** contains meta information about dataset such as date of creation, name and comments\n",
    "* **userinfo.txt** - contains meta information about user such as age, gender, name, location etc... \n",
    "* **fileinfo.txt** - contains meta information about the logged files such as start time, stop time, device id and others.\n",
    "* **activity.txt** - contains meta information about file, activity and comments.\n",
    "* **deviceConfig.json** - contains meta information about device configurations and logged sensors such as device id, device name, sensor type, name, measurement range etc...\n",
    "* **algoResults.txt** - contains meta information about file, algorithm reszlts and comments (**NOT USED TODAY**).\n",
    "\n",
    "***example dataset: meta structure***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: meta-files in directory C:\\Users\\ina8cob\\scripts\\tutorial_datalogger\\tutorial\\00_meta\n",
      "\tC:\\Users\\ina8cob\\scripts\\tutorial_datalogger\\tutorial\\00_meta\\activity.txt\n",
      "\tC:\\Users\\ina8cob\\scripts\\tutorial_datalogger\\tutorial\\00_meta\\algoResults.txt\n",
      "\tC:\\Users\\ina8cob\\scripts\\tutorial_datalogger\\tutorial\\00_meta\\datasetInfo.json\n",
      "\tC:\\Users\\ina8cob\\scripts\\tutorial_datalogger\\tutorial\\00_meta\\deviceConfig.json\n",
      "\tC:\\Users\\ina8cob\\scripts\\tutorial_datalogger\\tutorial\\00_meta\\fileInfo.txt\n",
      "\tC:\\Users\\ina8cob\\scripts\\tutorial_datalogger\\tutorial\\00_meta\\userInfo.txt\n"
     ]
    }
   ],
   "source": [
    "for datasetDir in datasetList:\n",
    "    hndlr = dlf.DatasetFormatHandler()\n",
    "    hndlr.list_metafiles(datasetDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Meta Information\n",
    "Dataset meta information contains: name of the dataset, date of creation, and description of the dataset given at time of creation by user/tester.<br>\n",
    "\n",
    "***code example for dataset meta extraction***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Test',\n",
       " 'description': 'newTimestamp',\n",
       " 'date_of_creation': '2020-10-28 17:50:57.941'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for datasetDir in datasetList:\n",
    "    hndlr = dlf.DatasetFormatHandler()\n",
    "    hndlr.get_datasetinfo(datasetDir)\n",
    "    display(hndlr.datasetinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Meta Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>country</th>\n",
       "      <th>nationality</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Karthick</td>\n",
       "      <td>29</td>\n",
       "      <td>Male</td>\n",
       "      <td>173</td>\n",
       "      <td>63</td>\n",
       "      <td>Cob</td>\n",
       "      <td>IND</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id      name  age gender  height  weight country nationality  \\\n",
       "0        3  Karthick   29   Male     173      63     Cob         IND   \n",
       "\n",
       "   experience  \n",
       "0           6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for datasetDir in datasetList:\n",
    "    hndlr = dlf.DatasetFormatHandler()\n",
    "    hndlr.get_userinfo(datasetDir)\n",
    "    display(hndlr.userinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files Meta Information\n",
    "'fileinfo.txt' contains information about logged files in the dataset. For every logged file following information will be stored:\n",
    "- file_name --> name of the file logged on the device\n",
    "- file_id --> contains the file_id / run id (same for the )\n",
    "\n",
    "***code example on the example dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_id</th>\n",
       "      <th>dev_id</th>\n",
       "      <th>comments</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOG_AFD0ED_1603887725768.bin</td>\n",
       "      <td>1603887725768</td>\n",
       "      <td>D0:53:08:AF:D0:ED</td>\n",
       "      <td>walk</td>\n",
       "      <td>2020-10-28 17:52:05.768</td>\n",
       "      <td>2020-10-28 17:52:58.131</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOG_AFD0ED_1603887786067.bin</td>\n",
       "      <td>1603887786067</td>\n",
       "      <td>D0:53:08:AF:D0:ED</td>\n",
       "      <td>test2</td>\n",
       "      <td>2020-10-28 17:53:06.067</td>\n",
       "      <td>2020-10-28 17:53:51.399</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file_name        file_id             dev_id comments  \\\n",
       "0  LOG_AFD0ED_1603887725768.bin  1603887725768  D0:53:08:AF:D0:ED     walk   \n",
       "1  LOG_AFD0ED_1603887786067.bin  1603887786067  D0:53:08:AF:D0:ED    test2   \n",
       "\n",
       "                start_time                stop_time  user_id  \n",
       "0  2020-10-28 17:52:05.768  2020-10-28 17:52:58.131        3  \n",
       "1  2020-10-28 17:53:06.067  2020-10-28 17:53:51.399        3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for datasetDir in datasetList:\n",
    "    hndlr = dlf.DatasetFormatHandler()\n",
    "    hndlr.get_fileinfo(datasetDir)\n",
    "    display(hndlr.fileinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device Configuration Meta Information\n",
    "Device configurations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys in the device dict and sensor dict\n",
      "dict_keys(['file_name', 'file_id', 'dev_id', 'dev_loc', 'dev_fw', 'dev_name', 'type', 'sensors'])\n",
      "dict_keys(['dev_id', 'sensor_type', 'name', 'range', 'bw', 'odr', 'unit', 'samplingfreq'])\n",
      "\n",
      "full device config dict content: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'file_name': 'LOG_AFD0ED_1603887725768.bin',\n",
       " 'file_id': '1603887725768',\n",
       " 'dev_id': 'D0:53:08:AF:D0:ED',\n",
       " 'dev_loc': 'LEFT',\n",
       " 'dev_fw': 'V1.3.0',\n",
       " 'dev_name': 'BST-DataLogger',\n",
       " 'type': 'DEVICE',\n",
       " 'sensors': [{'dev_id': 'D0:53:08:AF:D0:ED',\n",
       "   'sensor_type': 'PRESSURE',\n",
       "   'name': 'BMP390',\n",
       "   'range': None,\n",
       "   'bw': None,\n",
       "   'odr': 'SENSOR_ENV_ODR_25_HZ',\n",
       "   'unit': 'Physical units',\n",
       "   'samplingfreq': '25'},\n",
       "  {'dev_id': 'D0:53:08:AF:D0:ED',\n",
       "   'sensor_type': 'ACCEL',\n",
       "   'name': 'BMI270_ACCEL',\n",
       "   'range': 'SENSOR_ACCEL_RANGE_8G',\n",
       "   'bw': 'SENSOR_ACCEL_BW_NORMAL_AVG4',\n",
       "   'odr': 'SENSOR_ODR_100HZ',\n",
       "   'unit': 'LSB',\n",
       "   'samplingfreq': '100'},\n",
       "  {'dev_id': 'D0:53:08:AF:D0:ED',\n",
       "   'sensor_type': 'GYRO',\n",
       "   'name': 'BMI270_GYRO',\n",
       "   'range': 'SENSOR_GYRO_RANGE_2000_DPS',\n",
       "   'bw': 'SENSOR_GYRO_BW_NORMAL_MODE',\n",
       "   'odr': 'SENSOR_ODR_100HZ',\n",
       "   'unit': 'LSB',\n",
       "   'samplingfreq': '100'},\n",
       "  {'dev_id': 'D0:53:08:AF:D0:ED',\n",
       "   'sensor_type': 'MAG',\n",
       "   'name': 'BMM150',\n",
       "   'range': None,\n",
       "   'bw': None,\n",
       "   'odr': None,\n",
       "   'unit': 'LSB',\n",
       "   'samplingfreq': '100'},\n",
       "  {'dev_id': 'D0:53:08:AF:D0:ED',\n",
       "   'sensor_type': 'PROXIMITY',\n",
       "   'name': 'TMG4903',\n",
       "   'range': None,\n",
       "   'bw': None,\n",
       "   'odr': 'SENSOR_PROX_ODR_10HZ',\n",
       "   'unit': 'LSB',\n",
       "   'samplingfreq': '10'}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for datasetDir in datasetList:\n",
    "    hndlr = dlf.DatasetFormatHandler()\n",
    "    hndlr.get_device_configs(datasetDir)\n",
    "\n",
    "    print(\"keys in the device dict and sensor dict\")\n",
    "    print(hndlr.deviceconfigs[0].keys()) # show keys only device config for first file\n",
    "    print(hndlr.deviceconfigs[0][\"sensors\"][0].keys()) # show keys in sensors config for first file\n",
    "\n",
    "    print('\\nfull device config dict content: ')\n",
    "    display(hndlr.deviceconfigs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity Meta Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOG_AFD0ED_1603887725768.bin</td>\n",
       "      <td>1603887725768</td>\n",
       "      <td>STANDING_STILL</td>\n",
       "      <td>2020-10-28 17:52:05.768</td>\n",
       "      <td>2020-10-28 17:52:58.131</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOG_AFD0ED_1603887786067.bin</td>\n",
       "      <td>1603887786067</td>\n",
       "      <td>STANDING_STILL</td>\n",
       "      <td>2020-10-28 17:53:06.067</td>\n",
       "      <td>2020-10-28 17:53:51.399</td>\n",
       "      <td>test2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file_name        file_id        activity  \\\n",
       "0  LOG_AFD0ED_1603887725768.bin  1603887725768  STANDING_STILL   \n",
       "1  LOG_AFD0ED_1603887786067.bin  1603887786067  STANDING_STILL   \n",
       "\n",
       "                start_time                stop_time comments  \n",
       "0  2020-10-28 17:52:05.768  2020-10-28 17:52:58.131     walk  \n",
       "1  2020-10-28 17:53:06.067  2020-10-28 17:53:51.399    test2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for datasetDir in datasetList:\n",
    "    hndlr = dlf.DatasetFormatHandler()\n",
    "    hndlr.get_activityinfo(datasetDir)\n",
    "    display(hndlr.activityinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datalogger Format\n",
    "### binary-format\n",
    "see GLP_Decoder()\n",
    "### csv-format\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp[s]</th>\n",
       "      <th>packetcount</th>\n",
       "      <th>bmi270ax[lsb]</th>\n",
       "      <th>bmi270ay[lsb]</th>\n",
       "      <th>bmi270az[lsb]</th>\n",
       "      <th>bmi270gx[lsb]</th>\n",
       "      <th>bmi270gy[lsb]</th>\n",
       "      <th>bmi270gz[lsb]</th>\n",
       "      <th>bmi270t[degC]</th>\n",
       "      <th>bmm150mx[lsb]</th>\n",
       "      <th>bmm150my[lsb]</th>\n",
       "      <th>bmm150mz[lsb]</th>\n",
       "      <th>TMG_Prox[lsb]</th>\n",
       "      <th>bmp390p[hPa]</th>\n",
       "      <th>bmp390t[degC]</th>\n",
       "      <th>UnixTime[ms]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-690.0</td>\n",
       "      <td>2507.0</td>\n",
       "      <td>3165.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>29.931000</td>\n",
       "      <td>327.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>11136.0</td>\n",
       "      <td>961.906494</td>\n",
       "      <td>35.900002</td>\n",
       "      <td>1.603888e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-689.0</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>3163.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>29.922001</td>\n",
       "      <td>327.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>11136.0</td>\n",
       "      <td>961.906494</td>\n",
       "      <td>35.900002</td>\n",
       "      <td>1.603888e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp[s]  packetcount  bmi270ax[lsb]  bmi270ay[lsb]  bmi270az[lsb]  \\\n",
       "0          0.01          0.0         -690.0         2507.0         3165.0   \n",
       "1          0.02          1.0         -689.0         2514.0         3163.0   \n",
       "\n",
       "   bmi270gx[lsb]  bmi270gy[lsb]  bmi270gz[lsb]  bmi270t[degC]  bmm150mx[lsb]  \\\n",
       "0           -3.0           30.0           -1.0      29.931000          327.0   \n",
       "1            6.0           29.0           -1.0      29.922001          327.0   \n",
       "\n",
       "   bmm150my[lsb]  bmm150mz[lsb]  TMG_Prox[lsb]  bmp390p[hPa]  bmp390t[degC]  \\\n",
       "0          435.0          689.0        11136.0    961.906494      35.900002   \n",
       "1          435.0          689.0        11136.0    961.906494      35.900002   \n",
       "\n",
       "   UnixTime[ms]  \n",
       "0  1.603888e+12  \n",
       "1  1.603888e+12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for datasetDir in datasetList:\n",
    "    dataHandler = dlf.DatasetFormatHandler()\n",
    "    dataHandler.get_csvdata_files(datasetDir)\n",
    "    dataHandler.csvDataList[\"file_fullpath\"][0]\n",
    "\n",
    "    # read first file from csv list\n",
    "    data_df = dataHandler.read_csvfile(dataHandler.csvDataList[\"file_fullpath\"][0])\n",
    "    # display first 3 lines in csv-data file\n",
    "    display(data_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On: Using Datalogger Format Handler\n",
    "Example code for reading the dataset data and plotting the information including labels.\n",
    "\n",
    "Processing steps:\n",
    "1. list the meta files, data files and label files from the repository\n",
    "2. read the meta files, data files and label files from the repository\n",
    "3. read the data files, data files and label files from the repository\n",
    "4. plot the logged sensor data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] dataset repo \t C:\\Users\\ina8cob\\scripts\\tutorial_datalogger\\tutorial\n",
      "\n",
      "[INFO] processing file: C:\\Users\\ina8cob\\scripts\\tutorial_datalogger\\tutorial\\01_data\\csv\\LOG_AFD0ED_1603887725768.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['timestamp(s)'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-4406c70799db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msensor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msensors_cfg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0msensordata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_sensordata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0msenscfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_sensor_configs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot_idxL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplot_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\scripts\\tutorial_datalogger\\DataloggerFormatHandler.py\u001b[0m in \u001b[0;36mget_sensordata\u001b[1;34m(self, dataf, sensor_name)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[1;32m-> 2934\u001b[1;33m                                                    raise_missing=True)\n\u001b[0m\u001b[0;32m   2935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[0;32m   1353\u001b[0m                           raise_missing}\n\u001b[1;32m-> 1354\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[0;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1250\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'loc'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['timestamp(s)'] not in index\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 14) # plot size parameters\n",
    "\n",
    "# evaluate repositories and extract data, labels and visualize them\n",
    "for datasetDir in datasetList:\n",
    "    print(\"\\n[INFO] dataset repo \\t %s\"%(os.path.abspath(datasetDir)))\n",
    "    dataHandler = dlf.DatasetFormatHandler()\n",
    "    # 1. list the meta files, data files and label files from the repository\n",
    "    #dataHandler.list_metafiles(datasetDir)\n",
    "    #dataHandler.list_datacsvfiles(datasetDir)\n",
    "    #dataHandler.list_labelsfiles(datasetDir)\n",
    "\n",
    "    # 2. read the meta files, \n",
    "    dataHandler.get_fileinfo(datasetDir)\n",
    "    dataHandler.get_activityinfo(datasetDir)\n",
    "    dataHandler.get_userinfo(datasetDir)\n",
    "    dataHandler.get_device_configs(datasetDir)\n",
    "    \n",
    "    # 3. data files and label files from the repository\n",
    "    dataHandler.get_csvdata_files(datasetDir)\n",
    "    dataHandler.get_bindata_files(datasetDir)\n",
    "    dataHandler.get_labels_files(datasetDir)\n",
    "\n",
    "    # 4. do process the files and plot data and labels\n",
    "    for fileName in dataHandler.csvDataList[\"file_fullpath\"]:        \n",
    "        print(\"\\n[INFO] processing file: %s\"%(fileName))\n",
    "        \n",
    "        # get index of the file to be processed\n",
    "        file_idx = dataHandler.csvDataList[\"file_fullpath\"].index(fileName)\n",
    "        \n",
    "        # read data from csv file\n",
    "        data_df = dataHandler.read_csvfile(fileName)\n",
    "        data_filename = dataHandler.csvDataList[\"file_name\"][file_idx]\n",
    "        \n",
    "        for labelName in dataHandler.labelDataList[\"file_name\"]:\n",
    "            \n",
    "            # get index of the file to be processed\n",
    "            label_idx = dataHandler.labelDataList[\"file_name\"].index(labelName)\n",
    "            label_filename = dataHandler.labelDataList[\"file_name\"][label_idx]\n",
    "            \n",
    "            if data_filename in label_filename:\n",
    "                # read labels\n",
    "                label_df = dataHandler.read_labelsfile(dataHandler.labelDataList[\"file_fullpath\"][label_idx])\n",
    "                labels_in_file = dataHandler.get_labelnames(label_df)\n",
    "\n",
    "                # \n",
    "                labelsList = []\n",
    "                t_start = dataHandler.fileinfo[\"start_time\"][label_idx]\n",
    "                t_vec = data_df[\"timestamp[s]\"]*dataHandler.TIME_DT\n",
    "                # extract labels with same id\n",
    "                for iii in range(len(labels_in_file[\"label_id\"])):\n",
    "                    same_labels = dataHandler.extract_labels_with_sameid(label_df, labels_in_file[\"label_id\"][iii])\n",
    "                    label_sig = dataHandler.create_labelsignals(t_vec,t_start,same_labels)\n",
    "                    labelsList.append(label_sig)\n",
    "        \n",
    "        # read sensor configs for the logged file\n",
    "        sensors_cfg = dataHandler.config_get_sensors(dataHandler.binDataList[\"file_name\"][file_idx])\n",
    "        \n",
    "        # plot sensor data\n",
    "        plot_idxL = len(sensors_cfg)+1\n",
    "        plot_idx = 1\n",
    "        \n",
    "        plt.figure()\n",
    "\n",
    "        for sensor in sensors_cfg:\n",
    "            sensordata = dataHandler.get_sensordata(data_df,sensor[\"name\"])\n",
    "            senscfg = dataHandler.get_sensor_configs(sensor)            \n",
    "            plt.subplot(plot_idxL,1,plot_idx)\n",
    "            dataHandler.plot_data(sensordata,senscfg[\"name\"], dataHandler.TIME_DT, senscfg[\"lsb2unit\"], title=dataHandler.csvDataList[\"file_name\"][file_idx])\n",
    "            plot_idx += 1\n",
    "        \n",
    "        for labelName in dataHandler.labelDataList[\"file_name\"]:\n",
    "            \n",
    "            # get index of the file to be processed\n",
    "            label_idx = dataHandler.labelDataList[\"file_name\"].index(labelName)\n",
    "            label_filename = dataHandler.labelDataList[\"file_name\"][label_idx]\n",
    "            \n",
    "            if data_filename in label_filename:\n",
    "                # plot labels\n",
    "                plt.subplot(plot_idxL,1,plot_idx)\n",
    "                plt.title('labels '+dataHandler.csvDataList[\"file_name\"][file_idx])\n",
    "                for idx in range(len(labelsList)):\n",
    "                    plt.plot(labelsList[idx][\"time\"],labelsList[idx][\"label_id\"],label=labels_in_file[\"label_name\"][idx])\n",
    "                plt.xlabel('time (s)')\n",
    "                plt.ylabel('label_id')\n",
    "                plt.legend()\n",
    "                plt.grid()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
